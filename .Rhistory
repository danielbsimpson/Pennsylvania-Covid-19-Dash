abline(lm.fit, col = "red")
newdata1 <- seq(20, 280, by = 50)
conf_int <- predict(lm.fit, newdata = data.frame(horsepower = newdata1), interval = "confidence", level = 0.99)
pred_int <- predict(lm.fit, newdata = data.frame(horsepower = newdata1), interval = "prediction", level = 0.99)
lines(newdata1, conf_int[,2], col="blue", lty=4)
lines(newdata1, conf_int[,3], col="blue", lty=4)
lines(newdata1, pred_int[,2], col="purple", lty=5)
lines(newdata1, pred_int[,3], col="purple", lty=5)
legend("topright", legend = c("Regression line", "Confidence Interval", "Predictor Interval"), col = c("red", "blue","purple"), lty = c(1,4,5), cex = 0.8)
newdata1
plot(Auto$weight, Auto$mpg, xlab = "Weight", ylab = "MPG", main = "MPG vs Weight")
lm.fit <- lm(Auto$mpg ~ Auto$weight, Auto)
abline(lm.fit, col = 'green')
legend("topright", legend = "Regression Line", lty = 1, col = "green")
summary(lm.fit)
plot(Auto$weight, Auto$acceleration, xlab = "Weight", ylab = "Acceleration", main = "Acceleration vs Weight")
lm.fit <- lm(Auto$acceleration ~ Auto$weight, Auto)
abline(lm.fit, col = 'red')
legend("topright", legend = "Regression Line", lty = 1, col = "red")
summary(lm.fit)
plot(Auto$mpg, Auto$displacement, xlab = "MPG", ylab = "Displacement", main = "MPG vs Displacement")
lm.fit <- lm(Auto$displacement ~ Auto$mpg, Auto)
abline(lm.fit, col = 'blue')
legend("topright", legend = "Regression Line", lty = 1, col = "blue")
summary(lm.fit)
library(ISLR)
mydata <- Auto
summary(Auto)
sapply(Auto[,-c(7,8,9)], var)
plot(Auto[,-c(7,8,9)], lower.panel = NULL)
library(corrplot)
correlation_matrix <- cor(Auto[,-c(7,8,9)])
corrplot(correlation_matrix, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
lm.fit <- lm(mpg ~ horsepower, data = mydata)
plot(mydata$horsepower, mydata$mpg,
xlab="horsepower", ylab = "mpg",
main = "Horsepower vs MPG with regression line",
ylim = c(0,60), xlim = c(30,280))
abline(lm.fit, col = "red")
legend("topright", legend = "Regression Line", lty = 1, col = "red")
summary(lm.fit)
plot(mydata$horsepower, mydata$mpg,
xlab="Horsepower", ylab = "MPG",
main = "Horsepower vs MPG",
ylim = c(5,50), xlim = c(40,245))
abline(lm.fit, col = "red")
newdata1 <- seq(20, 280, by = 50)
conf_int <- predict(lm.fit, newdata = data.frame(horsepower = newdata1), interval = "confidence", level = 0.99)
pred_int <- predict(lm.fit, newdata = data.frame(horsepower = newdata1), interval = "prediction", level = 0.99)
lines(newdata1, conf_int[,2], col="blue", lty=4)
lines(newdata1, conf_int[,3], col="blue", lty=4)
lines(newdata1, pred_int[,2], col="purple", lty=5)
lines(newdata1, pred_int[,3], col="purple", lty=5)
legend("topright", legend = c("Regression line", "Confidence Interval", "Predictor Interval"), col = c("red", "blue","purple"), lty = c(1,4,5), cex = 0.8)
predict(lm.fit, data.frame(horsepower = 89))
predict(lm.fit, data.frame(horsepower = 89), interval = "confidence", level = 0.99)
predict(lm.fit, data.frame(horsepower = 89), interval = "prediction", level = 0.99)
plot(Auto$weight, Auto$mpg, xlab = "Weight", ylab = "MPG", main = "MPG vs Weight")
lm.fit <- lm(Auto$mpg ~ Auto$weight, Auto)
abline(lm.fit, col = 'green')
legend("topright", legend = "Regression Line", lty = 1, col = "green")
summary(lm.fit)
plot(Auto$weight, Auto$acceleration, xlab = "Weight", ylab = "Acceleration", main = "Acceleration vs Weight")
lm.fit <- lm(Auto$acceleration ~ Auto$weight, Auto)
abline(lm.fit, col = 'red')
legend("topright", legend = "Regression Line", lty = 1, col = "red")
summary(lm.fit)
plot(Auto$mpg, Auto$displacement, xlab = "MPG", ylab = "Displacement", main = "MPG vs Displacement")
lm.fit <- lm(Auto$displacement ~ Auto$mpg, Auto)
abline(lm.fit, col = 'blue')
legend("topright", legend = "Regression Line", lty = 1, col = "blue")
summary(lm.fit)
library(ISLR)
mydata <- Auto
summary(Auto)
sapply(Auto[,-c(7,8,9)], var)
plot(Auto[,-c(7,8,9)], lower.panel = NULL)
library(corrplot)
correlation_matrix <- cor(Auto[,-c(7,8,9)])
corrplot(correlation_matrix, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
lm.fit <- lm(mpg ~ horsepower, data = mydata)
plot(mydata$horsepower, mydata$mpg,
xlab="horsepower", ylab = "mpg",
main = "Horsepower vs MPG with regression line",
ylim = c(0,60), xlim = c(30,280))
abline(lm.fit, col = "red")
legend("topright", legend = "Regression Line", lty = 1, col = "red")
summary(lm.fit)
plot(Auto$weight, Auto$mpg, xlab = "Weight", ylab = "MPG", main = "MPG vs Weight")
lm.fit <- lm(Auto$mpg ~ Auto$weight, Auto)
abline(lm.fit, col = 'green')
legend("topright", legend = "Regression Line", lty = 1, col = "green")
summary(lm.fit)
plot(Auto$weight, Auto$acceleration, xlab = "Weight", ylab = "Acceleration", main = "Acceleration vs Weight")
lm.fit <- lm(Auto$acceleration ~ Auto$weight, Auto)
abline(lm.fit, col = 'red')
legend("topright", legend = "Regression Line", lty = 1, col = "red")
summary(lm.fit)
plot(Auto$mpg, Auto$displacement, xlab = "MPG", ylab = "Displacement", main = "MPG vs Displacement")
lm.fit <- lm(Auto$displacement ~ Auto$mpg, Auto)
abline(lm.fit, col = 'blue')
legend("topright", legend = "Regression Line", lty = 1, col = "blue")
summary(lm.fit)
plot(mydata$horsepower, mydata$mpg,
xlab="Horsepower", ylab = "MPG",
main = "Horsepower vs MPG",
ylim = c(5,50), xlim = c(40,245))
abline(lm.fit, col = "red")
newdata1 <- seq(20, 280, by = 50)
conf_int <- predict(lm.fit, newdata = data.frame(horsepower = newdata1), interval = "confidence", level = 0.99)
pred_int <- predict(lm.fit, newdata = data.frame(horsepower = newdata1), interval = "prediction", level = 0.99)
lines(newdata1, conf_int[,2], col="blue", lty=4)
plot(mydata$horsepower, mydata$mpg,
xlab="Horsepower", ylab = "MPG",
main = "Horsepower vs MPG",
ylim = c(5,50), xlim = c(40,245))
lm.fit <- lm(mpg ~ horsepower, data = mydata)
abline(lm.fit, col = "red")
newdata1 <- seq(20, 280, by = 50)
conf_int <- predict(lm.fit, newdata = data.frame(horsepower = newdata1), interval = "confidence", level = 0.99)
pred_int <- predict(lm.fit, newdata = data.frame(horsepower = newdata1), interval = "prediction", level = 0.99)
lines(newdata1, conf_int[,2], col="blue", lty=4)
lines(newdata1, conf_int[,3], col="blue", lty=4)
lines(newdata1, pred_int[,2], col="purple", lty=5)
lines(newdata1, pred_int[,3], col="purple", lty=5)
legend("topright", legend = c("Regression line", "Confidence Interval", "Predictor Interval"), col = c("red", "blue","purple"), lty = c(1,4,5), cex = 0.8)
plot(Auto$weight, Auto$acceleration, xlab = "Weight", ylab = "Acceleration", main = "Acceleration vs Weight")
plot(Auto$mpg, Auto$acceleration, xlab = "Weight", ylab = "Acceleration", main = "Acceleration vs Weight")
library(ISLR)
mydata <- Auto
summary(Auto)
sapply(Auto[,-c(7,8,9)], var)
plot(Auto[,-c(7,8,9)], lower.panel = NULL)
library(corrplot)
correlation_matrix <- cor(Auto[,-c(7,8,9)])
corrplot(correlation_matrix, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
lm.fit <- lm(mpg ~ horsepower, data = mydata)
plot(mydata$horsepower, mydata$mpg,
xlab="horsepower", ylab = "mpg",
main = "Horsepower vs MPG",
ylim = c(0,60), xlim = c(30,280))
abline(lm.fit, col = "red")
legend("topright", legend = "Regression Line", lty = 1, col = "red")
summary(lm.fit)
plot(Auto$weight, Auto$mpg, xlab = "Weight", ylab = "MPG", main = "MPG vs Weight")
lm.fit <- lm(Auto$mpg ~ Auto$weight, Auto)
abline(lm.fit, col = 'green')
legend("topright", legend = "Regression Line", lty = 1, col = "green")
summary(lm.fit)
plot(Auto$mpg, Auto$acceleration, xlab = "Weight", ylab = "Acceleration", main = "Acceleration vs Weight")
lm.fit <- lm(Auto$acceleration ~ Auto$mpg, Auto)
abline(lm.fit, col = 'red')
legend("topright", legend = "Regression Line", lty = 1, col = "red")
summary(lm.fit)
plot(Auto$mpg, Auto$displacement, xlab = "MPG", ylab = "Displacement", main = "MPG vs Displacement")
lm.fit <- lm(Auto$displacement ~ Auto$mpg, Auto)
abline(lm.fit, col = 'blue')
legend("topright", legend = "Regression Line", lty = 1, col = "blue")
summary(lm.fit)
plot(mydata$horsepower, mydata$mpg,
xlab="Horsepower", ylab = "MPG",
main = "Horsepower vs MPG",
ylim = c(5,50), xlim = c(40,245))
lm.fit <- lm(mpg ~ horsepower, data = mydata)
abline(lm.fit, col = "red")
newdata1 <- seq(20, 280, by = 50)
conf_int <- predict(lm.fit, newdata = data.frame(horsepower = newdata1), interval = "confidence", level = 0.99)
pred_int <- predict(lm.fit, newdata = data.frame(horsepower = newdata1), interval = "prediction", level = 0.99)
lines(newdata1, conf_int[,2], col="blue", lty=4)
lines(newdata1, conf_int[,3], col="blue", lty=4)
lines(newdata1, pred_int[,2], col="purple", lty=5)
lines(newdata1, pred_int[,3], col="purple", lty=5)
legend("topright", legend = c("Regression line", "Confidence Interval", "Predictor Interval"), col = c("red", "blue","purple"), lty = c(1,4,5), cex = 0.8)
predict(lm.fit, data.frame(horsepower = 89))
predict(lm.fit, data.frame(horsepower = 89), interval = "confidence", level = 0.99)
predict(lm.fit, data.frame(horsepower = 89), interval = "prediction", level = 0.99)
plot(Auto$mpg, Auto$acceleration, xlab = "MPG", ylab = "Acceleration", main = "Acceleration vs MPG")
lm.fit <- lm(Auto$acceleration ~ Auto$mpg, Auto)
abline(lm.fit, col = 'red')
legend("topright", legend = "Regression Line", lty = 1, col = "red")
summary(lm.fit)
library(readr)
library(dplyr)
library(tree)
library(cluster)
library(datasets)
library(rpart)
library(rpart.plot)
library(e1071)
library(ROCR)
RoomOccupancy_train <- read.csv("C:\\Users\\Damien\\Desktop\\Course Work MSc Data Science\\Big Data with R\\Homework\\Homework 2\\RoomOccupancy_Training.txt")
RoomOccupancy_test <- read.csv("C:\\Users\\Damien\\Desktop\\Course Work MSc Data Science\\Big Data with R\\Homework\\Homework 2\\RoomOccupancy_Testing.txt")
RoomOccupancy_train$Occupancy <- as.factor(RoomOccupancy_train$Occupancy)
RoomOccupancy_test$Occupancy <- as.factor(RoomOccupancy_test$Occupancy)
tree.Room <- tree(Occupancy ~ ., RoomOccupancy_train)
summary(tree.Room)
tree.Room.pred <- predict(tree.Room,newdata = RoomOccupancy_test,type="class")
summary(tree.Room.pred)
mean(tree.Room.pred!= RoomOccupancy_test$Occupancy)
table(tree.Room.pred, RoomOccupancy_test$Occupancy, dnn=c("Prediction", "Actual"))
plot(tree.Room)
text(tree.Room, cex = 0.75)
plot(tree.Room, type = "uniform")
text(tree.Room,pretty=5, col = 2:6, font = 4, cex = .75)
library(randomForest)
set.seed(404)
random.forest.Occupancy <- randomForest(Occupancy ~ ., data = RoomOccupancy_train, importance = TRUE)
print(random.forest.Occupancy)
random.forest.pred <- predict(random.forest.Occupancy, newdata = RoomOccupancy_test)
summary(random.forest.pred)
table(random.forest.pred, RoomOccupancy_test$Occupancy, dnn=c("Prediction", "Actual"))
print((179+53)/ 300)
importance(random.forest.Occupancy)
varImpPlot(random.forest.Occupancy, main = "Importance of each feature")
barplot(sort(importance(random.forest.Occupancy)[,3], decreasing = TRUE),
main = "Importance of each feature",
xlab = "Features",
ylab = "Relative Importance",
horiz = FALSE,
col = "red",
las = 1,
cex.names = 0.7
)
wine.train <- read.csv("C:\\Users\\Damien\\Desktop\\Course Work MSc Data Science\\Big Data with R\\Homework\\Homework 2\\WineQuality_training.txt")
wine.test <- read.csv("C:\\Users\\Damien\\Desktop\\Course Work MSc Data Science\\Big Data with R\\Homework\\Homework 2\\WineQuality_testing.txt")
summary(wine.train)
fit.svm <- svm(quality ~ ., data = wine.train, kernel = "linear", cost = 0.1, scale = FALSE)
summary(fit.svm)
set.seed(404)
grid.search.svm <- tune(svm, quality ~ ., data = wine.train, kernel = "linear", ranges = list(cost = c(0.01, 0.1, 1, 5, 10)))
summary(grid.search.svm)
best.model.grid.search <- grid.search.svm$best.model
summary(best.model.grid.search)
svm.pred <- predict(best.model.grid.search, newdata = wine.test)
summary(svm.pred)
mean(svm.pred != wine.test$quality)
table(svm.pred,wine.test$quality, dnn=c("Prediction", "Actual"))
svm.radial <- tune(svm, quality ~ ., data = wine.train, kernel = "radial", ranges = list(cost = c(0.01,0.1,1,5,10), gamma = c(0.01,0.03,0.1,0.5,1)))
summary(svm.radial)
svm.radial.pred <- predict(svm.radial$best.model, newdata = wine.test)
mean(svm.radial.pred != wine.test$quality)
table(svm.radial.pred,wine.test$quality, dnn=c("Prediction", "Actual"))
rocplot = function(pred, truth, ...){
predob = prediction(pred,truth)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)}
svm.fit.radial <- svm(quality ~., data = wine.train, kernel = "radial", gamma = 1, cost = 10, decision.values = TRUE)
fitted.radial <- attributes(predict(svm.fit.radial, newdata = wine.test, decision.values = TRUE))
par(mfrow = c(1,1))
rocplot(fitted.radial$decision.values[,1], wine.test["quality"], col = "red")
svm.fit.linear <- svm(quality ~., data = wine.train, kernel = "linear", cost = 5, decision.values = TRUE)
fitted.linear <- attributes(predict(svm.fit.linear, newdata = wine.test, decision.values = TRUE))
rocplot(fitted.linear$decision.values[,1], wine.test["quality"], add = TRUE)
legend(.8,0.2, legend = c("Radial", "Linear"), col = c("red", "black"), lty = 1:1)
USA.data <- USArrests
Heir.Cluster <- hclust(dist(USA.data, method = "euclidean"), method = "complete")
plot(Heir.Cluster, cex = 0.55, xlab = "State Names", ylab = NULL, sub = "Hierarchical Cluster")
Cut.Heir.Cluster <- cutree(Heir.Cluster, 3)
sorted.Cluster <- sort(Cut.Heir.Cluster)
Cluster1.Names <- names(sorted.Cluster[1:16])
print(Cluster1.Names)
Cluster2.Names <- names(sorted.Cluster[17:30])
print(Cluster2.Names)
Cluster3.Names <- names(sorted.Cluster[31:50])
print(Cluster3.Names)
plot(Heir.Cluster, cex = 0.55, xlab = "State Names",ylab = NULL, sub = "Hierarchical Cluster")
rect.hclust(Heir.Cluster, k=3, border=2:6)
Heir.Cluster.Scale <- hclust(dist(scale(USA.data), method = "euclidean"), method = "complete")
plot(Heir.Cluster.Scale, xlab = "State Names", main = "Scaled Heirarchical Cluster", cex = 0.55, ylab = NULL, sub = "Hierarchical Cluster")
rect.hclust(Heir.Cluster, k=3, border=2:6)
Cut.Heir.Cluster.Scale <- cutree(Heir.Cluster.Scale, k =3)
table(Cut.Heir.Cluster)
table(Cut.Heir.Cluster.Scale)
sorted.Cluster.Scale <- sort(Cut.Heir.Cluster.Scale)
Cluster1.Names.Scale <- names(sorted.Cluster.Scale[1:8])
print(Cluster1.Names.Scale)
Cluster2.Names.Scale <- names(sorted.Cluster.Scale[9:19])
print(Cluster2.Names.Scale)
Cluster3.Names.Scale <- names(sorted.Cluster.Scale[20:50])
print(Cluster3.Names.Scale)
set.seed(404)
my.data <- rbind(matrix(rnorm(20*50, mean=1, sd = 1), nrow = 20),
matrix(rnorm(20*50, mean=10, sd = 1), nrow = 20),
matrix(rnorm(20*50, mean=20, sd = 1), nrow = 20))
true_class = c(rep(1,20), rep(2,20), rep(3,20))
PCA.my.data <- prcomp(my.data, scale = TRUE)
summary(PCA.my.data)
my.data.pca = prcomp(my.data)$x
plot(my.data.pca[,1:2], col=c(rep(1,20), rep(3,20), rep(5,20)))
biplot(PCA.my.data)
k.means.my.data <- kmeans(my.data, 3, nstart = 1)
print("Total within-cluster sum of squares:")
k.means.my.data$tot.withinss
plot(my.data, col =(k.means.my.data$cluster +1), main="K-Means result with 3 clusters", pch=20, cex=2)
table(k.means.my.data$cluster, true_class, dnn=c("Prediction", "Actual"))
print("K-means cluster:")
print(k.means.my.data$cluster)
print("True Class:")
print(true_class)
set.seed(1)
k.means.my.data.2 <- kmeans(my.data, 2, nstart = 20)
print("Total within-cluster sum of squares:")
k.means.my.data.2$tot.withinss
plot(my.data, col =(k.means.my.data.2$cluster +1), main="K-Means result with 2 clusters", pch=20, cex=2)
set.seed(1)
k.means.my.data.4 <- kmeans(my.data, 4, nstart = 100)
print("Total within-cluster sum of squares:")
k.means.my.data.4$tot.withinss
plot(my.data, col =(k.means.my.data.4$cluster +1), main="K-Means result with 4 clusters", pch=20, cex=2)
tot.WithinSS <- rep(0,6)
for(i in 1:6){
set.seed(1)
tot.WithinSS[i] <- kmeans(my.data, i, nstart = 100)$tot.withinss
}
plot(1:6, tot.WithinSS, type = "b", xlab = "Number of Clusters", ylab = "Total within groups sum of squares",
main = "Elbow graph for Optimal Cluster number", pch = 10, cex = 2, col = "green"
)
set.seed(1)
k.means.out <- kmeans(my.data.pca[, 1:2], 3, nstart = 20)
table(true_class, k.means.out$cluster, dnn=c("Prediction", "Actual"))
print("K-means cluster:")
print(k.means.out$cluster)
print("True Class:")
print(true_class)
set.seed(404)
k.means.out.scale <- kmeans(scale(my.data), 3, nstart = 100)
table(true_class, k.means.out.scale$cluster, dnn=c("Prediction", "Actual"))
print("K-means cluster:")
print(k.means.out.scale$cluster)
print("True Class:")
print(true_class)
print(USArrests)
library(cluster)
library(datasets)
USA.data <- USArrests
Heir.Cluster <- hclust(dist(USA.data, method = "euclidean"), method = "complete")
plot(Heir.Cluster, cex = 0.55, xlab = "State Names", ylab = NULL, sub = "Hierarchical Cluster")
Cut.Heir.Cluster <- cutree(Heir.Cluster, 3)
sorted.Cluster <- sort(Cut.Heir.Cluster)
Cluster1.Names <- names(sorted.Cluster[1:16])
print(Cluster1.Names)
Cluster2.Names <- names(sorted.Cluster[17:30])
print(Cluster2.Names)
Cluster3.Names <- names(sorted.Cluster[31:50])
print(Cluster3.Names)
plot(Heir.Cluster, cex = 0.55, xlab = "State Names",ylab = NULL, sub = "Hierarchical Cluster")
rect.hclust(Heir.Cluster, k=3, border=2:6)
Heir.Cluster.Scale <- hclust(dist(scale(USA.data), method = "euclidean"), method = "complete")
plot(Heir.Cluster.Scale, xlab = "State Names", main = "Scaled Heirarchical Cluster", cex = 0.55, ylab = NULL, sub = "Hierarchical Cluster")
rect.hclust(Heir.Cluster, k=3, border=2:6)
library(cluster)
library(datasets)
USA.data <- USArrests
Heir.Cluster <- hclust(dist(USA.data, method = "euclidean"), method = "complete")
plot(Heir.Cluster, cex = 0.55, xlab = "State Names", ylab = NULL, sub = "Hierarchical Cluster")
Cut.Heir.Cluster <- cutree(Heir.Cluster, 3)
sorted.Cluster <- sort(Cut.Heir.Cluster)
Cluster1.Names <- names(sorted.Cluster[1:16])
print(Cluster1.Names)
Cluster2.Names <- names(sorted.Cluster[17:30])
print(Cluster2.Names)
Cluster3.Names <- names(sorted.Cluster[31:50])
print(Cluster3.Names)
plot(Heir.Cluster, cex = 0.55, xlab = "State Names",ylab = NULL, sub = "Hierarchical Cluster")
rect.hclust(Heir.Cluster, k=3, border=2:6)
Heir.Cluster.Scale <- hclust(dist(scale(USA.data), method = "euclidean"), method = "complete")
plot(Heir.Cluster.Scale, xlab = "State Names", main = "Scaled Heirarchical Cluster", cex = 0.55, ylab = NULL, sub = "Hierarchical Cluster")
rect.hclust(Heir.Cluster, k=3, border=2:6)
Cut.Heir.Cluster.Scale <- cutree(Heir.Cluster.Scale, k =3)
table(Cut.Heir.Cluster)
table(Cut.Heir.Cluster.Scale)
sorted.Cluster.Scale <- sort(Cut.Heir.Cluster.Scale)
Cluster1.Names.Scale <- names(sorted.Cluster.Scale[1:8])
print(Cluster1.Names.Scale)
Cluster2.Names.Scale <- names(sorted.Cluster.Scale[9:19])
print(Cluster2.Names.Scale)
Cluster3.Names.Scale <- names(sorted.Cluster.Scale[20:50])
print(Cluster3.Names.Scale)
x <- c(2,5,8,9,30,35,38,38,42)
summary(x)
x1 <- c(10,3,2,6,4)
y1 <- c(1,4,-3,2,6)
cov(x1,y1)
setwd("C:/Users/Damien/Desktop/Data Science Projects/Pennsylvania-Covid-19-Dash/")
covid_data <- read.csv('PA_time_series_data.csv')
covid_data <- covid_data[!(covid_data$Admin2=="Out of PA" | covid_data$Admin2 == "Unassigned"),]
#adams <- subset(covid_data, Admin2 == 'Adams' & Confirmed >= 1)
#adams$date <- as.Date(adams$Date , format = "%Y-%m-%d")
#df_adams <- data.frame(dates = adams$date, I = adams$Daily.Confirmed)
library(EpiEstim)
library(ggplot2)
#adams_r <- estimate_R(df_adams, method="parametric_si", config = make_config(list(mean_si = 3.96, std_si = 4.75)))
#plot(adams_r, legend = FALSE)
print(unique(covid_data$Admin2))
for(i in unique(covid_data$Admin2)){
assign(paste(i), data.frame(subset(covid_data,
Admin2 == i & Confirmed >= 1,
select = c(Daily.Confirmed))))
}
for(i in unique(covid_data$Admin2)){
assign(paste(i), estimate_R(i,
method = "parametric_si",
config = make_config(list(mean_si = 3.96,
std_si = 4.75))))
}
View(Adams)
for(i in unique(covid_data$Admin2)){
assign(paste(i, '_name', sep = ''), i)
}
setwd("C:/Users/Damien/Desktop/Data Science Projects/Pennsylvania-Covid-19-Dash/")
covid_data <- read.csv('PA_time_series_data.csv')
covid_data <- covid_data[!(covid_data$Admin2=="Out of PA" | covid_data$Admin2 == "Unassigned"),]
#adams <- subset(covid_data, Admin2 == 'Adams' & Confirmed >= 1)
#adams$date <- as.Date(adams$Date , format = "%Y-%m-%d")
#df_adams <- data.frame(dates = adams$date, I = adams$Daily.Confirmed)
library(EpiEstim)
library(ggplot2)
#adams_r <- estimate_R(df_adams, method="parametric_si", config = make_config(list(mean_si = 3.96, std_si = 4.75)))
#plot(adams_r, legend = FALSE)
print(unique(covid_data$Admin2))
for(i in unique(covid_data$Admin2)){
assign(paste(i), estimate_R(data.frame(subset(covid_data,
Admin2 == i & Confirmed >= 1,
select = c(Daily.Confirmed)))),
method = "parametric_si",
config = make_config(list(mean_si = 3.96,
std_si = 4.75)))
}
setwd("C:/Users/Damien/Desktop/Data Science Projects/Pennsylvania-Covid-19-Dash/")
covid_data <- read.csv('PA_time_series_data.csv')
covid_data <- covid_data[!(covid_data$Admin2=="Out of PA" | covid_data$Admin2 == "Unassigned"),]
#adams <- subset(covid_data, Admin2 == 'Adams' & Confirmed >= 1)
#adams$date <- as.Date(adams$Date , format = "%Y-%m-%d")
#df_adams <- data.frame(dates = adams$date, I = adams$Daily.Confirmed)
library(EpiEstim)
library(ggplot2)
#adams_r <- estimate_R(df_adams, method="parametric_si", config = make_config(list(mean_si = 3.96, std_si = 4.75)))
#plot(adams_r, legend = FALSE)
print(unique(covid_data$Admin2))
for(i in unique(covid_data$Admin2)){
assign(paste(i), estimate_R(data.frame(subset(covid_data,
Admin2 == i & Confirmed >= 1,
select = c(Daily.Confirmed))),
method = "parametric_si",
config = make_config(list(mean_si = 3.96,
std_si = 4.75))))
}
View(Northumberland)
View(Northumberland)
View(Allegheny)
Allegheny[["dates"]]
plot(Adams, legend = False)
plot(Adams, legend = FALSE)
View(Adams)
Adams[["dates"]]
print(unique(covid_data$Admin2))
# for(i in unique(covid_data$Admin2)){
#   assign(paste(i), estimate_R(i,
#                               method = "parametric_si",
#                               config = make_config(list(mean_si = 3.96,
#                                                         std_si = 4.75))))
#          }
for(i in unique(covid_data$Admin2)){
assign(paste(i, '_name', sep = ''), i)
}
plot(Adams, "R")
ls()
ls()
setwd("C:/Users/Damien/Desktop/Data Science Projects/Pennsylvania-Covid-19-Dash/")
covid_data <- read.csv('PA_time_series_data.csv')
covid_data <- covid_data[!(covid_data$Admin2=="Out of PA" | covid_data$Admin2 == "Unassigned"),]
#adams <- subset(covid_data, Admin2 == 'Adams' & Confirmed >= 1)
#adams$date <- as.Date(adams$Date , format = "%Y-%m-%d")
#df_adams <- data.frame(dates = adams$date, I = adams$Daily.Confirmed)
library(EpiEstim)
library(ggplot2)
#adams_r <- estimate_R(df_adams, method="parametric_si", config = make_config(list(mean_si = 3.96, std_si = 4.75)))
#plot(adams_r, legend = FALSE)
print(unique(covid_data$Admin2))
for(i in unique(covid_data$Admin2)){
assign(paste(i), estimate_R(data.frame(subset(covid_data,
Admin2 == i & Confirmed >= 1,
select = c(Daily.Confirmed))),
method = "parametric_si",
config = make_config(list(mean_si = 3.96,
std_si = 4.75))))
}
names(mydata)
names()
names(ls())
ls()
mydata
for(i in unique(covid_data$Admin2)){plot(i, "R")}
plot(Adam, "R", title(main = "Adam County"))
plot(Adams, "R", title(main = "Adam County"))
plot(Adams, "R")
View(Adams)
Adams[["R"]]
tail(Adams[["R"]])
tail(Adams[["R"]],1)
tail(Adams[["R"]][c('t_start', 't_end')],1)
tail(Adams[["R"]][c('Mean(R)', 'Quantile.0.05(R)', 'Quantile.0.95(R)')],1)
Adams_new <- tail(Adams[["R"]][c('Mean(R)', 'Quantile.0.05(R)', 'Quantile.0.95(R)')],1)
Adams_new
View(Adams_new)
View(Adams_new)
County <- c('Adams')
DataFrame.Adams1 <- data.frame(County, Adams_new)
View(DataFrame.Adams1)
